{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957f8924-a154-4fb4-866b-99e8dc343868",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4db80-3bd9-478f-ac84-323cb42d0195",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "## Mission - Élaborez le modèle de scoring\n",
    "------------------------------\n",
    "\n",
    "Vous êtes Data Scientist au sein d'une société financière, nommée **\"Prêt à dépenser\"**, qui propose des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt.\n",
    "\n",
    "L’entreprise souhaite **mettre en œuvre un outil de “scoring crédit” pour calculer la probabilité** qu’un client rembourse son crédit, puis classifier la demande en crédit accordé ou refusé. Elle souhaite donc développer un **algorithme de classification** en s’appuyant sur des sources de données variées (données comportementales, données provenant d'autres institutions financières, etc.)\n",
    "\n",
    "**Votre mission :**\n",
    "* Construire un modèle de scoring qui donnera une prédiction sur la probabilité de faillite d'un client de façon automatique.\n",
    "* Analyser les features qui contribuent le plus au modèle, d’une manière générale (feature importance globale) et au niveau d’un client (feature importance locale), afin, dans un soucis de transparence, de permettre à un chargé d’études de mieux comprendre le score attribué par le modèle.\n",
    "* Mettre en production le modèle de scoring de prédiction à l’aide d’une API et réaliser une interface de test de cette API.\n",
    "* Mettre en œuvre une approche globale MLOps de bout en bout, du tracking des expérimentations à l’analyse en production du data drift.\n",
    "\n",
    "Michaël, votre manager, vous incite à sélectionner un ou des kernels Kaggle pour vous faciliter l’analyse exploratoire, la préparation des données et le feature engineering nécessaires à l’élaboration du modèle de scoring. \n",
    "\n",
    "Voici le mail qu’il vous a envoyé.\n",
    "\n",
    "*Bonjour,*\n",
    "\n",
    "*Afin de pouvoir faire évoluer régulièrement le modèle, je souhaite tester la mise en œuvre une démarche de type MLOps d’automatisation et d’industrialisation de la gestion du cycle de vie du modèle.*\n",
    "\n",
    "*Vous trouverez en pièce jointe **la liste d’outils à utiliser** pour créer une plateforme MLOps qui s’appuie sur des outils Open Source.* \n",
    "\n",
    "*Je souhaite que vous puissiez mettre en oeuvre au minimum **les étapes orientées MLOps** suivantes :* \n",
    "* *Dans le notebook d’entraînement des modèles, générer à l’aide de MLFlow un tracking d'expérimentations*\n",
    "* *Lancer l’interface web 'UI MLFlow\" d'affichage des résultats du tracking*\n",
    "* *Réaliser avec MLFlow un stockage centralisé des modèles dans un “model registry”*\n",
    "* *Tester le serving MLFlow*\n",
    "* *Gérer le code avec le logiciel de version Git*\n",
    "* *Partager le code sur Github pour assurer une intégration continue*\n",
    "* *Utiliser Github Actions pour le déploiement continu et automatisé du code de l’API sur le cloud*\n",
    "* *Concevoir des tests unitaires avec Pytest (ou Unittest) et les exécuter de manière automatisée lors du build réalisé par Github Actions*\n",
    " \n",
    "*J’ai également rassemblé des conseils pour vous aider à vous lancer dans ce projet !*\n",
    "\n",
    "*Concernant **l’élaboration du modèle** soyez vigilant sur deux points spécifiques au contexte métier :* \n",
    "* *Le déséquilibre entre le nombre de bons et de moins bons clients doit être pris en compte pour élaborer un modèle pertinent, avec une méthode au choix*\n",
    "* *Le déséquilibre du coût métier entre un faux négatif (FN - mauvais client prédit bon client : donc crédit accordé et perte en capital) et un faux positif (FP - bon client prédit mauvais : donc refus crédit et manque à gagner en marge)*\n",
    "    * *Vous pourrez supposer, par exemple, que le coût d’un FN est dix fois supérieur au coût d’un FP*\n",
    "    * *Vous créerez un score “métier” (minimisation du coût d’erreur de prédiction des FN et FP) pour comparer les modèles, afin de choisir le meilleur modèle et ses meilleurs hyperparamètres. Attention cette minimisation du coût métier doit passer par l’optimisation du seuil qui détermine, à partir d’une probabilité, la classe 0 ou 1 (un “predict” suppose un seuil à 0.5 qui n’est pas forcément l’optimum)*\n",
    "    * *En parallèle, maintenez pour comparaison et contrôle des mesures plus techniques, telles que l’AUC et l’accuracy*\n",
    " \n",
    "*D’autre part je souhaite que vous mettiez en œuvre une démarche d’élaboration des modèles avec **Cross-Validation et optimisation des hyperparamètres, via GridsearchCV ou équivalent.***\n",
    "\n",
    "*Un dernier conseil : si vous obtenez des scores supérieurs au 1er du challenge Kaggle (AUC > 0.82), posez-vous la question si vous n’avez pas de l’overfitting dans votre modèle !*\n",
    "\n",
    "*Vous exposerez votre **modèle de prédiction sous forme d’une API** qui permet de calculer la probabilité de défaut du client, ainsi que sa classe (accepté ou refusé) en fonction du seuil optimisé d’un point de vue métier.*\n",
    "\n",
    "***Le déploiement de l’API** sera réalisée sur une plateforme Cloud, de préférence une solution gratuite.*\n",
    "\n",
    "*Je vous propose d’utiliser un Notebook ou une application Streamlit pour réaliser en local  l’**interface de test de l’API**.*\n",
    "\n",
    "*Bon courage !*\n",
    "\n",
    "*Mickael*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2395d9-9a2f-469e-aa27-517d22c74c61",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3ea2ece-8f2e-4665-bdf6-ecda225ed69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Global \n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# MLFlow\n",
    "import mlflow\n",
    "\n",
    "# Optuna\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "459a9a8f-417b-4bf4-a803-d1a9a357e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7062543-4e5f-418e-a828-9b141682486d",
   "metadata": {},
   "source": [
    "# Lecture du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a4c391-b439-4962-924b-9ac588817f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to data\n",
    "path = \"./data/\"\n",
    "# List files in the data directory\n",
    "file_list = os.listdir(path)\n",
    "# Create an empty dict to store the file name as key and a DataFrame as value\n",
    "df_dict = {}\n",
    "# Create a list to store file names\n",
    "filenames_list = []\n",
    "# Go through the list and get the name of the file without extension\n",
    "for file in file_list:\n",
    "    # Get the name of the file and its extension\n",
    "    name, extension = os.path.splitext(file)\n",
    "    # Append the name of the file to the dedicated list\n",
    "    filenames_list.append(name)\n",
    "    # Exclude \"HomeCredit_columns_description.csv\" which is not usefull for our purpose\n",
    "    if file != \"HomeCredit_columns_description.csv\":\n",
    "        # Append the dataframe read to the list\n",
    "        df_dict[name] = pd.read_csv(path+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222b35f-a68a-4efe-a570-8996e59d8231",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fbf58a-ead0-4830-823d-3ba9e2ce91b2",
   "metadata": {},
   "source": [
    "Pour la préparation des données nous nous appuierons sur le kernel Kaggle suivant : <a href=\"https://www.kaggle.com/code/jsaguiar/lightgbm-with-simple-features/script\">LightGBM with Simple Features</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da37e8c-defc-458f-889b-584ac6fcf685",
   "metadata": {},
   "source": [
    "Au préalable, définissons une fonction nous permettant d'effectuer un OneHotEnconding sur les variables catégorielles.\n",
    "\n",
    "Celle-ci nous retournera le dataframe modifié après l'encoding et une liste des nouvelles colonnes créées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256e55c2-b6c1-4c4a-a957-57ee244fcd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encode(data, nan_as_category=True):\n",
    "    # Store the name of original columns\n",
    "    original_columns = list(data.columns)\n",
    "    # Retrieve categorical columns\n",
    "    categorical_columns = [col for col in data.columns if data[col].dtype == \"object\"]\n",
    "    # Proceed with OneHotEncoding\n",
    "    data = pd.get_dummies(data, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    # List new columns\n",
    "    new_columns = [c for c in data.columns if c not in original_columns]\n",
    "    # Return the dataframe and the list of new columns\n",
    "    return data, new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbae52-f957-42a6-82f4-03986dfdc980",
   "metadata": {},
   "source": [
    "Premièrement intéressons nous aux dataframes \"application\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8132309c-3ba0-4e0f-a6a3-16c8d49d0630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train and test dataframes\n",
    "df = pd.concat([df_dict[\"application_train\"], df_dict[\"application_test\"]]).reset_index(drop=True)\n",
    "\n",
    "# Remove XNA gender\n",
    "df = df[df[\"CODE_GENDER\"] != \"XNA\"]\n",
    "\n",
    "# Binary encode two state categorical features\n",
    "for binary_features in [\"NAME_CONTRACT_TYPE\", \"CODE_GENDER\", \"FLAG_OWN_CAR\", \"FLAG_OWN_REALTY\"]:\n",
    "    df[binary_features], uniques = pd.factorize(df[binary_features])\n",
    "    \n",
    "# OneHot Encode categorical features\n",
    "df, applications_cat_cols = one_hot_encode(df, False)\n",
    "\n",
    "# Replace 365243 by NaN in DAYS_EMPLOYED column\n",
    "df.loc[df[\"DAYS_EMPLOYED\"]==365243, [\"DAYS_EMPLOYED\"]] = np.nan\n",
    "\n",
    "# Generate new features by calculating percentages\n",
    "df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a9e22d-5efb-4aeb-a5fc-215e259c953f",
   "metadata": {},
   "source": [
    "A présent, intéressons nous aux dataframes \"bureau\" et \"bureau_balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fcf52a4-2fa0-4923-8546-aff38d38952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "df_dict[\"bureau\"], bureau_cat_cols = one_hot_encode(df_dict[\"bureau\"], True)\n",
    "\n",
    "# OneHot Encode categorical features\n",
    "df_dict[\"bureau_balance\"], bureau_balance_cat_cols = one_hot_encode(df_dict[\"bureau_balance\"], True)\n",
    "\n",
    "# Aggregation of bureau_balance dataframe on SK_ID_BUREAU\n",
    "aggregations = {\n",
    "    \"MONTHS_BALANCE\": [\"min\", \"max\", \"size\"], \n",
    "}\n",
    "for col in bureau_balance_cat_cols:\n",
    "    aggregations[col] = [\"mean\"]\n",
    "# Groupby \"SK_ID_BUREAU\"\n",
    "bb_agg = df_dict[\"bureau_balance\"].groupby(\"SK_ID_BUREAU\").agg(aggregations)\n",
    "# Rename columns\n",
    "bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "\n",
    "# Merge bureau and bureau_balance dataframes\n",
    "bureau = df_dict[\"bureau\"].join(bb_agg, how=\"left\", on=\"SK_ID_BUREAU\")\n",
    "# Drop SK_ID_BUREAU column, which is a reference between bureau and bureau_balance dataframes\n",
    "bureau.drop([\"SK_ID_BUREAU\"], axis=1, inplace= True)\n",
    "\n",
    "# Aggregation of bureau dataframe\n",
    "# Build numeric features in bureau dataframe\n",
    "num_aggregations = {\n",
    "    \"DAYS_CREDIT\": [\"min\", \"max\", \"mean\", \"var\"],\n",
    "    \"DAYS_CREDIT_ENDDATE\": [\"min\", \"max\", \"mean\"],\n",
    "    \"DAYS_CREDIT_UPDATE\": [\"mean\"],\n",
    "    \"CREDIT_DAY_OVERDUE\": [\"max\", \"mean\"],\n",
    "    \"AMT_CREDIT_MAX_OVERDUE\": [\"mean\"],\n",
    "    \"AMT_CREDIT_SUM\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_CREDIT_SUM_DEBT\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_CREDIT_SUM_OVERDUE\": [\"mean\"],\n",
    "    \"AMT_CREDIT_SUM_LIMIT\": [\"mean\", \"sum\"],\n",
    "    \"AMT_ANNUITY\": [\"max\", \"mean\"],\n",
    "    \"CNT_CREDIT_PROLONG\": [\"sum\"],\n",
    "    \"MONTHS_BALANCE_MIN\": [\"min\"],\n",
    "    \"MONTHS_BALANCE_MAX\": [\"max\"],\n",
    "    \"MONTHS_BALANCE_SIZE\": [\"mean\", \"sum\"],\n",
    "}\n",
    "# Build categorical features\n",
    "cat_aggregations = {}\n",
    "for cat in bureau_cat_cols: cat_aggregations[cat] = [\"mean\"]\n",
    "for cat in bureau_balance_cat_cols: cat_aggregations[cat + \"_MEAN\"] = [\"mean\"]\n",
    "# Groupby \"SK_ID_CURR\"\n",
    "bureau_agg = bureau.groupby(\"SK_ID_CURR\").agg({**num_aggregations, **cat_aggregations})\n",
    "# Rename columns\n",
    "bureau_agg.columns = pd.Index([\"BURO_\" + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "# Generate features for active credits\n",
    "# Get all active credits\n",
    "active = bureau[bureau[\"CREDIT_ACTIVE_Active\"] == 1]\n",
    "# Groupby \"SK_ID_CURR\" with the same aggregations params for numerical features only\n",
    "active_agg = active.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "# Rename columns\n",
    "active_agg.columns = pd.Index([\"ACTIVE_\" + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "# Join bureau_agg and active_agg dataframes\n",
    "bureau_agg = bureau_agg.join(active_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "# Generate features for closed credits\n",
    "# Get all closed credits\n",
    "closed = bureau[bureau[\"CREDIT_ACTIVE_Closed\"] == 1]\n",
    "# Groupby \"SK_ID_CURR\" with the same aggregations params for numerical features only\n",
    "closed_agg = closed.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "# Rename columns\n",
    "closed_agg.columns = pd.Index([\"CLOSED_\" + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "# Join bureau_agg and active_agg dataframes\n",
    "bureau_agg = bureau_agg.join(closed_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "# Join df and new bureau_agg dataframes\n",
    "df = df.join(bureau_agg, how=\"left\", on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae4a408-8fa0-4f82-8878-4b92f42318e0",
   "metadata": {},
   "source": [
    "Passons au dataframe \"previous_application\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0b965e8-1651-4190-a29d-71d0d0ccf841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "df_dict[\"previous_application\"], prev_app_cat_cols = one_hot_encode(df_dict[\"previous_application\"], True)\n",
    "\n",
    "# Replace 365243 days by NaN \n",
    "df_dict[\"previous_application\"].loc[\n",
    "    df_dict[\"previous_application\"][\"DAYS_FIRST_DRAWING\"] == 365243, [\"DAYS_FIRST_DRAWING\"] \n",
    "] = np.nan\n",
    "df_dict[\"previous_application\"].loc[\n",
    "    df_dict[\"previous_application\"][\"DAYS_FIRST_DUE\"] == 365243, [\"DAYS_FIRST_DUE\"] \n",
    "] = np.nan\n",
    "df_dict[\"previous_application\"].loc[\n",
    "    df_dict[\"previous_application\"][\"DAYS_LAST_DUE_1ST_VERSION\"] == 365243, [\"DAYS_LAST_DUE_1ST_VERSION\"] \n",
    "] = np.nan\n",
    "df_dict[\"previous_application\"].loc[\n",
    "    df_dict[\"previous_application\"][\"DAYS_LAST_DUE\"] == 365243, [\"DAYS_LAST_DUE\"] \n",
    "] = np.nan\n",
    "df_dict[\"previous_application\"].loc[\n",
    "    df_dict[\"previous_application\"][\"DAYS_TERMINATION\"] == 365243, [\"DAYS_TERMINATION\"] \n",
    "] = np.nan\n",
    "\n",
    "# Add feature : value ask / value received percentage\n",
    "df_dict[\"previous_application\"]['APP_CREDIT_PERC'] = \\\n",
    "    df_dict[\"previous_application\"]['AMT_APPLICATION'] / df_dict[\"previous_application\"]['AMT_CREDIT']\n",
    "\n",
    "# Aggregation of previous_application dataframe\n",
    "# Previous applications numeric features\n",
    "num_aggregations = {\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "    'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'AMT_GOODS_PRICE': ['min', 'max', 'mean'],\n",
    "    'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "}\n",
    "# Previous applications categorical features\n",
    "cat_aggregations = {}\n",
    "for cat in prev_app_cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "# Groupby \"SK_ID_CURR\"\n",
    "prev_agg = df_dict[\"previous_application\"].groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "# Rename columns\n",
    "prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "# Generate features for approved applications\n",
    "# Get all approved applications\n",
    "approved = df_dict[\"previous_application\"][df_dict[\"previous_application\"][\"NAME_CONTRACT_STATUS_Approved\"] == 1]\n",
    "# Groupby \"SK_ID_CURR\" with the same aggregations params for numerical features only\n",
    "approved_agg = approved.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "# Rename columns\n",
    "approved_agg.columns = pd.Index([\"APPROVED_\" + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "# Join prev_agg and approved_agg dataframes\n",
    "prev_agg = prev_agg.join(approved_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "# Generate features for refused applications\n",
    "# Get all refused applications\n",
    "refused = df_dict[\"previous_application\"][df_dict[\"previous_application\"][\"NAME_CONTRACT_STATUS_Refused\"] == 1]\n",
    "# Groupby \"SK_ID_CURR\" with the same aggregations params for numerical features only\n",
    "refused_agg = refused.groupby(\"SK_ID_CURR\").agg(num_aggregations)\n",
    "# Rename columns\n",
    "refused_agg.columns = pd.Index([\"REFUSED_\" + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "# Join prev_agg and refused_agg dataframes\n",
    "prev_agg = prev_agg.join(refused_agg, how=\"left\", on=\"SK_ID_CURR\")\n",
    "\n",
    "# Join df and new bureau_agg dataframes\n",
    "df = df.join(prev_agg, how=\"left\", on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471c7642-2387-4705-8fdc-49cbaaf36c42",
   "metadata": {},
   "source": [
    "Au tour du dataframe \"POS_CASH_balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "813aa7c3-af9c-4bea-9f58-4b97fd296afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "df_dict[\"POS_CASH_balance\"], pos_cat_cols = one_hot_encode(df_dict[\"POS_CASH_balance\"], True)\n",
    "\n",
    "# Aggregation of POS_CASH_balance dataframe\n",
    "# POS_CASH_balance numeric features\n",
    "aggregations = {\n",
    "    \"MONTHS_BALANCE\": [\"max\", \"mean\", \"size\"],\n",
    "    \"SK_DPD\": [\"max\", \"mean\"],\n",
    "    \"SK_DPD_DEF\": [\"max\", \"mean\"],\n",
    "}\n",
    "# POS_CASH_balance categorical features\n",
    "for cat in pos_cat_cols:\n",
    "    aggregations[cat] = [\"mean\"]\n",
    "# Groupby \"SK_ID_CURR\"\n",
    "pos_agg = df_dict[\"POS_CASH_balance\"].groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "# Rename columns\n",
    "pos_agg.columns = pd.Index([\"POS_\" + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "# Count POS CASH accounts\n",
    "pos_agg[\"POS_COUNT\"] = df_dict[\"POS_CASH_balance\"].groupby(\"SK_ID_CURR\").size\n",
    "\n",
    "# Join df and new pos_agg dataframes\n",
    "df = df.join(pos_agg, how=\"left\", on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adf4d04-2963-4b73-b0a8-289254011c7d",
   "metadata": {},
   "source": [
    "Puis du dataframe \"installments_payments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0e5d80-339d-400b-a0f3-8483d465b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "df_dict[\"installments_payments\"], install_cat_cols = one_hot_encode(df_dict[\"installments_payments\"], True)\n",
    "\n",
    "# Percentage and difference paid in each installment (amount paid and installment value)\n",
    "df_dict[\"installments_payments\"][\"PAYMENT_PERC\"] = \\\n",
    "    df_dict[\"installments_payments\"][\"AMT_PAYMENT\"] / df_dict[\"installments_payments\"][\"AMT_INSTALMENT\"]\n",
    "df_dict[\"installments_payments\"][\"PAYMENT_DIFF\"] = \\\n",
    "    df_dict[\"installments_payments\"][\"AMT_INSTALMENT\"] - df_dict[\"installments_payments\"][\"AMT_PAYMENT\"]\n",
    "# Days past due and days before due (no negative values)\n",
    "df_dict[\"installments_payments\"][\"DPD\"] = \\\n",
    "    df_dict[\"installments_payments\"][\"DAYS_ENTRY_PAYMENT\"] - df_dict[\"installments_payments\"][\"DAYS_INSTALMENT\"]\n",
    "df_dict[\"installments_payments\"][\"DBD\"] = \\\n",
    "    df_dict[\"installments_payments\"][\"DAYS_INSTALMENT\"] - df_dict[\"installments_payments\"][\"DAYS_ENTRY_PAYMENT\"]\n",
    "df_dict[\"installments_payments\"][\"DPD\"] = \\\n",
    "    df_dict[\"installments_payments\"][\"DPD\"].apply(lambda x: x if x > 0 else 0)\n",
    "df_dict[\"installments_payments\"][\"DBD\"] = \\\n",
    "    df_dict[\"installments_payments\"][\"DBD\"].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "# Aggregation of installments_payments dataframe\n",
    "# installments_payments numeric features\n",
    "aggregations = {\n",
    "    \"NUM_INSTALMENT_VERSION\": [\"nunique\"],\n",
    "    \"DPD\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"DBD\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"PAYMENT_PERC\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "    \"PAYMENT_DIFF\": [\"max\", \"mean\", \"sum\", \"var\"],\n",
    "    \"AMT_INSTALMENT\": [\"max\", \"mean\", \"sum\"],\n",
    "    \"AMT_PAYMENT\": [\"min\", \"max\", \"mean\", \"sum\"],\n",
    "    \"DAYS_ENTRY_PAYMENT\": [\"max\", \"mean\", \"sum\"],\n",
    "}\n",
    "# installments_payments categorical features\n",
    "for cat in install_cat_cols:\n",
    "    aggregations[cat] = [\"mean\"]\n",
    "# Groupby \"SK_ID_CURR\"\n",
    "ins_agg = df_dict[\"installments_payments\"].groupby(\"SK_ID_CURR\").agg(aggregations)\n",
    "# Rename columns\n",
    "ins_agg.columns = pd.Index([\"INSTAL_\" + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "# Count POS CASH accounts\n",
    "ins_agg[\"INSTAL_COUNT\"] = df_dict[\"installments_payments\"].groupby(\"SK_ID_CURR\").size\n",
    "\n",
    "# Join df and new ins_agg dataframes\n",
    "df = df.join(ins_agg, how=\"left\", on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64c853-823e-40e7-a528-fd6892b88405",
   "metadata": {},
   "source": [
    "Et enfin du dataframe \"credit_card_balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "527d6be2-5301-4139-8abd-355af4697742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encode categorical features\n",
    "df_dict[\"credit_card_balance\"], credit_cat_cols = one_hot_encode(df_dict[\"credit_card_balance\"], True)\n",
    "\n",
    "# General aggregations\n",
    "df_dict[\"credit_card_balance\"].drop([\"SK_ID_PREV\"], axis= 1, inplace = True)\n",
    "cc_agg = df_dict[\"credit_card_balance\"].groupby(\"SK_ID_CURR\").agg([\"min\", \"max\", \"mean\", \"sum\", \"var\"])\n",
    "cc_agg.columns = pd.Index([\"CC_\" + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "# Count credit card lines\n",
    "cc_agg[\"CC_COUNT\"] = df_dict[\"credit_card_balance\"].groupby(\"SK_ID_CURR\").size()\n",
    "\n",
    "# Join df and new cc_agg dataframes\n",
    "df = df.join(cc_agg, how=\"left\", on=\"SK_ID_CURR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6a7bf5-76ca-409d-a1e9-ee1a6f49acea",
   "metadata": {},
   "source": [
    "Séparons à présent nos données en jeux d'entrainement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ea4b556-f748-4568-9cb7-cc2459dbc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide in training/validation and test data\n",
    "train_df = pd.DataFrame(df[df['TARGET'].notnull()])\n",
    "test_df = pd.DataFrame(df[df['TARGET'].isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3570d70f-f7ed-4afd-ab16-ca3e830ae9ff",
   "metadata": {},
   "source": [
    "# Vérification des correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd37d7-9ecf-4250-b141-9fd799536d14",
   "metadata": {},
   "source": [
    "Vérifions qu'après la création de nos features, nous n'avons pas de correlations trop fortes avec notre cible, auquel cas ces variables seraient supprimées pour éviter le data leakage.\n",
    "\n",
    "Tout d'abord, nous vérifierons les corrrelations de Pearson, puis les correlations de Spearman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63edac67-23f0-47fe-8646-299f11dcec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute pearson correlation matrix\n",
    "pearson = train_df.corr(method=\"pearson\", numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93808cc4-ea26-486d-9a71-3ff010830438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute spearman correlation matrix\n",
    "spearman = train_df.corr(method=\"spearman\", numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87b577c7-beb0-40a3-88fa-4c3bcb0b3a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET    1.0\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for correlations or anti correlations with the target of more than 70%\n",
    "pearson[\"TARGET\"].loc[(pearson[\"TARGET\"] > 0.7) | (pearson[\"TARGET\"] < -0.7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed3b9591-27bb-439f-a1ed-c038ab7a5d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET    1.0\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for correlations or anti correlations with the target of more than 70%\n",
    "spearman[\"TARGET\"].loc[(spearman[\"TARGET\"] > 0.7) | (spearman[\"TARGET\"] < -0.7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3142e6-db99-49e9-9335-7f7a51d091b7",
   "metadata": {},
   "source": [
    "Aucune correlation ne semble trop importante avec notre cible !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a0e3b7-96e8-4c6d-854b-b49f697bb194",
   "metadata": {},
   "source": [
    "# Fonction de scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aa0e9f-0c7d-44e4-a52b-6c062972d497",
   "metadata": {},
   "source": [
    "Afin de nous adapter au mieux à la problématique métier, nous allons définir une fonction afin de calculer un \"score métier\".\n",
    "\n",
    "En effet, il existe un déséquilibre du coût métier entre un faux négatif (un mauvais client prédit comme bon client : donc crédit accordé et perte de capital) et un faux positif (bon client prédit mauvais : refus de crédit et donc manque à gagner en marge). On suppose que le coût d'un faux négatif est 10 fois supérieur à celui d'un faux positif.\n",
    "\n",
    "Pour cela, nous calculerons un \"gain\" que fera la société comme suit :\n",
    "* les vrais positifs rapportent de l'argent et sont donc pondérés à 1\n",
    "* les faux positifs font perdre de l'argent mais moins que les faux négatifs et sont donc pondérés à -0.01\n",
    "* les faux négatifs font également perdre de l'argent mais plus que les faux négatifs et sont donc pondérés à -0.1\n",
    "* les vrais négatifs ne rapportent pas d'argent et n'en font pas perdre non plus donc sont ignorés\n",
    "\n",
    "Note : les coéfficients de pondération seront éventuellemnt à modifier selon les observations effectuées sur le comportement lors de l'entrainement des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9cb0d4eb-32a6-477d-80b4-fb4f4160179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_business_score(true_vals, pred_vals, fn_coeff=-0.1, fp_coeff=-0.01):\n",
    "    \"\"\"\n",
    "    Compute a business score to evaluate our models\n",
    "    Goal : penalize false negative compared to false positive\n",
    "    --------------------\n",
    "    Arguments :\n",
    "        true_vals : array-like : correct values\n",
    "        pred_vals : array-like : predicted values\n",
    "        fn_coeff : optionnal, float, between 0 and 1 : coefficient to apply to false negative values\n",
    "        fp_coeff : optionnal, float, between 0 and 1 : coefficient to apply to false positive values\n",
    "    --------------------\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(true_vals, pred_vals).ravel()\n",
    "    \n",
    "    score = tp + fp_coeff*fp + fn_coeff*fn\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1697db-ea9e-42ff-a713-8b3b964e09d6",
   "metadata": {},
   "source": [
    "Testons notre fonction avec plusieurs listes de valeurs :\n",
    "* valeurs vraies : [0, 1, 1]\n",
    "* introduction d'un faux positif : [1, 1, 1]\n",
    "* introduction d'un faux négatif : [0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36f72718-3f68-4ed2-81d3-4ae75c403cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of values\n",
    "correct_values = [0, 1, 1]\n",
    "false_positive_values = [1, 1, 1]\n",
    "false_negative_values = [0, 1, 0]\n",
    "\n",
    "# Compute scores\n",
    "perfect_score = compute_business_score(correct_values, correct_values)\n",
    "fp_score = compute_business_score(correct_values, false_positive_values)\n",
    "fn_score = compute_business_score(correct_values, false_negative_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d66c3fa-35bc-4864-9859-c05265a66275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perfect_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ffcfb4aa-3aaa-4e46-896b-abf2eff58068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.99"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bad1e763-8c08-421e-aeb4-8892b2615be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4dfb4f-2819-493b-b59c-63caf634ac0f",
   "metadata": {},
   "source": [
    "On constate bien que notre score diminue fortement en présence d'un faux négatif comme attendu, à l'inverse du score avec un faux positif qui diminue nettement moins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdca34-c97b-4895-885b-69380c1343b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
